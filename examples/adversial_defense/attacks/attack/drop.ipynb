{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30099,
     "status": "ok",
     "timestamp": 1645110063656,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "f8rzILId95fb",
    "outputId": "cff712b2-309e-42ef-d736-eaac7f601c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\python39.zip', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\DLLs', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env', '', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages\\\\win32', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages\\\\win32\\\\lib', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages\\\\Pythonwin', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model/logs', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model/', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log', 'E:/BJCWorkshop/LPF-Defense-main/model/log', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/', 'E:/BJCWorkshop/LPF-Defense-main/model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('E:/BJCWorkshop/LPF-Defense-main/model')\n",
    "print(sys.path)\n",
    "# Removed Google Colab specific code\n",
    "\n",
    "# Example of setting a local path\n",
    "# local_path = 'E:/BJCWorkshop/LPF-Defense-main/model/Data/'\n",
    "\n",
    "# Use local_path in your code where you need to access files\n",
    "# For example, loading a file:\n",
    "# data = np.load(local_path + 'train_data_attack.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1645110063659,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "eDWbXFtL5Ra1",
    "outputId": "13cda7ab-6f21-4ac7-c2b0-78495cc81291"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/drive/MyDrive/Kimia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 8478,
     "status": "ok",
     "timestamp": 1645110072122,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "_CUlQEFa1KmW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import importlib\n",
    "from torchvision import transforms\n",
    "from data_utils.ModelNetDataLoader import ModelNetDataLoader, load_data, PointSampler, Normalize, RandomNoise, RandomRotate, toTensor\n",
    "import importlib.util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645110072123,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "RVc55fTV_rNm",
    "outputId": "c1c200c5-50a0-4eb6-d05e-fef8b78f678c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "      device = torch.device('cuda:0')\n",
    "      print('running on GPU')\n",
    "else:\n",
    "      device = torch.device('cpu')\n",
    "      print('running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBdk06DE1LSU"
   },
   "source": [
    "# Dynamic Saliency Map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please specify the path to the models based on your setup.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pointnet and pointnet2 run the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4363,
     "status": "ok",
     "timestamp": 1644915977125,
     "user": {
      "displayName": "Kimia N",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17812946252473362585"
     },
     "user_tz": -210
    },
    "id": "KWltn36e3lsE",
    "outputId": "1ab30334-0d9e-4da2-a43f-28815f65ad58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\python39.zip', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\DLLs', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env', '', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages\\\\win32', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages\\\\win32\\\\lib', 'd:\\\\anaconda3\\\\envs\\\\pytorch_env\\\\lib\\\\site-packages\\\\Pythonwin', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/model/models/', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model/logs', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model/', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log', 'E:/BJCWorkshop/LPF-Defense-main/model/log', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification', 'E:/BJCWorkshop/LPF-Defense-main/', 'E:/BJCWorkshop/LPF-Defense-main/model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model', 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model']\n",
      "['pointnet2_cls_ssg.py', 'pointnet2_utils.py', 'train_classification.py']\n",
      "<module 'pointnet2_cls_ssg' from 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model/pointnet2_cls_ssg.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26100\\3065997685.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(experiment_dir, 'checkpoints', 'best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "get_model(\n",
       "  (sa1): PointNetSetAbstraction(\n",
       "    (mlp_convs): ModuleList(\n",
       "      (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (mlp_bns): ModuleList(\n",
       "      (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (sa2): PointNetSetAbstraction(\n",
       "    (mlp_convs): ModuleList(\n",
       "      (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (mlp_bns): ModuleList(\n",
       "      (0-1): 2 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (sa3): PointNetSetAbstraction(\n",
       "    (mlp_convs): ModuleList(\n",
       "      (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (mlp_bns): ModuleList(\n",
       "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop1): Dropout(p=0.4, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop2): Dropout(p=0.4, inplace=False)\n",
       "  (fc3): Linear(in_features=256, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import importlib\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# # import model.train_classification as train_classification\n",
    "# # import model.eval_classification as eval_classification\n",
    "\n",
    "# # Add the directory containing pointnet to the Python path\n",
    "# # sys.path.append('E:/BJCWorkshop/LPF-Defense-main/model/models/')\n",
    "# sys.path.append('E:/BJCWorkshop/LPF-Defense-main/model/log/classification')\n",
    "\n",
    "# # Set experiment directory\n",
    "# experiment_dir = 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model'\n",
    "\n",
    "# # Set experiment directory\n",
    "# # log_dir = '001_model'\n",
    "# # experiment_dir = 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/' + log_dir\n",
    "\n",
    "# # num_class = 40\n",
    "\n",
    "# # List all Python files in the logs directory\n",
    "# log_files = [f for f in os.listdir(experiment_dir) if f.endswith('.py')]\n",
    "# if not log_files:\n",
    "#     raise FileNotFoundError(\"No Python files found in the logs directory.\")\n",
    "\n",
    "# print(log_files)\n",
    "\n",
    "# # Load the module from the file path\n",
    "# num_class = 40\n",
    "# model_name = log_files[0].split('.')[0]\n",
    "\n",
    "# # model_file_path = os.path.join(experiment_dir, model_name)\n",
    "# # spec = importlib.util.spec_from_file_location(\"pointnet2_cls_ssg\", model_file_path)\n",
    "# # model_module = importlib.util.module_from_spec(spec)\n",
    "# # sys.modules[\"pointnet2_cls_ssg\"] = model_module\n",
    "# # spec.loader.exec_module(model_module)\n",
    "\n",
    "\n",
    "# model_module = importlib.import_module(model_name)\n",
    "# print(model_module)\n",
    "# classifier = model_module.get_model(num_class, normal_channel=False)\n",
    "\n",
    "# # Load model weights\n",
    "# checkpoint = torch.load(os.path.join(experiment_dir, 'checkpoints', 'best_model.pth'))\n",
    "# classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# # Set device\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# classifier.to(device)\n",
    "\n",
    "# # Example operation: Evaluate model\n",
    "# classifier.eval()\n",
    "# with torch.no_grad():\n",
    "#     # Assuming data is preprocessed and ready for input\n",
    "#     local_path = 'E:/BJCWorkshop/LPF-Defense-main/model/Data/'\n",
    "#     data = np.load(os.path.join(local_path, 'train_data_attack.npy'))\n",
    "#     input_data = torch.from_numpy(data).float().to(device)\n",
    "#     output = classifier(input_data)\n",
    "#     print(output)\n",
    "\n",
    "\n",
    "\n",
    "# Clear sys.path of unnecessary paths\n",
    "sys.path = [p for p in sys.path if 'attacks' not in p]\n",
    "print(sys.path)\n",
    "\n",
    "# Add the correct directory to sys.path\n",
    "sys.path.append('E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model')\n",
    "experiment_dir = 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model'\n",
    "\n",
    "num_class = 40\n",
    "\n",
    "# List all Python files in the logs directory\n",
    "log_files = [f for f in os.listdir(experiment_dir) if f.endswith('.py')]\n",
    "if not log_files:\n",
    "    raise FileNotFoundError(\"No Python files found in the logs directory.\")\n",
    "\n",
    "print(log_files)\n",
    "\n",
    "# Load the module from the file path\n",
    "num_class = 40\n",
    "model_name = log_files[0].split('.')[0]\n",
    "model_module = importlib.import_module(model_name)\n",
    "print(model_module)\n",
    "# Path to the model file\n",
    "# model_file_path = 'E:/BJCWorkshop/LPF-Defense-main/model/log/classification/001_model/pointnet2_cls_ssg.py'\n",
    "\n",
    "# Load the module from the file path\n",
    "# spec = importlib.util.spec_from_file_location(\"pointnet2_cls_ssg\", model_file_path)\n",
    "# model_module = importlib.util.module_from_spec(spec)\n",
    "# sys.modules[\"pointnet2_cls_ssg\"] = model_module\n",
    "# spec.loader.exec_module(model_module)\n",
    "# print(model_module)\n",
    "criterion = model_module.get_loss()\n",
    "# Use the loaded module\n",
    "classifier = model_module.get_model(num_class=40, normal_channel=False)\n",
    "\n",
    "# Load model weights\n",
    "\n",
    "checkpoint = torch.load(os.path.join(experiment_dir, 'checkpoints', 'best_model.pth'))\n",
    "classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "classifier.to(device)\n",
    "\n",
    "# # Example operation: Evaluate model\n",
    "# classifier.eval()\n",
    "# with torch.no_grad():\n",
    "#     for data in testDataLoader:\n",
    "#         points, labels = data\n",
    "#         points = points.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         output = classifier(points)\n",
    "#         print(output)\n",
    "#         break  # Remove this break to process the entire dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DGCNN run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11094,
     "status": "ok",
     "timestamp": 1645110086114,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "GZGUxGJkL3lA",
    "outputId": "23e6eaf6-f406-4701-9550-40b6b8b905fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# DGCNN\n",
    "sys.path.append('E:/BJCWorkshop/LPF-Defense-main/attacks/')\n",
    "from DGCNN_cls import DGCNN, cal_loss\n",
    "# k = 20\n",
    "# emb_dims = 1024\n",
    "# dropout_p = 0.5\n",
    "# model = DGCNN(k, emb_dims, dropout_p, output_channels=40).to('cuda:0')\n",
    "# checkpoint = torch.load('log/DGCNN_checkpoint.pt')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the data, run the following cell. Specify paths based on your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1645110096631,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "2Mo6gxQm38Kl",
    "outputId": "da09da95-495e-4191-a6df-76478673db25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1024, 3])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "main_path = 'E:/BJCWorkshop/LPF-Defense-main/model'\n",
    "test_data_path = 'Data/test_data.npy'\n",
    "test_label_path = 'Data/test_labels.npy'\n",
    "test_X, test_y = load_data(main_path, test_data_path, test_label_path, mode='test')\n",
    "test_X, test_y = test_X.astype(np.float32), test_y.astype(np.int64)\n",
    "batch_size = test_X.shape[0]\n",
    "default_transform = transforms.Compose([Normalize(), toTensor()])\n",
    "\n",
    "test_dataset = ModelNetDataLoader(test_X, test_y, transform=default_transform)\n",
    "testDataLoader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=10)\n",
    "for data in testDataLoader:\n",
    "  break\n",
    "points, labels = data\n",
    "print(points.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1645110687539,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "38tog8zp1Iho"
   },
   "outputs": [],
   "source": [
    "def dynamic_saliency_map(model, points, labels, device, n=100, T=20, alpha=1):\n",
    "    model.eval()\n",
    "    saliency_points = np.zeros((points.shape[0], 3, n))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    points = points.transpose(1, 2).float()  # B * 3 * 1024\n",
    "    a = int(n/T)\n",
    "    for i in range(T):\n",
    "        points = points.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # computing the gradient of the loss with respect to the points\n",
    "        points.requires_grad = True\n",
    "        \n",
    "        # pointnet, pointnet++\n",
    "        # **************************\n",
    "        pred, trans_feat = classifier(points)\n",
    "        loss = criterion(pred, labels.long(), trans_feat)\n",
    "        # **************************\n",
    "        \n",
    "        # dgcnn\n",
    "        # **************************\n",
    "        # pred,_ = model(points)\n",
    "        # loss = cal_loss(pred, labels.long())\n",
    "        # ***************************\n",
    "         # Check if loss requires grad\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            grad = points.grad\n",
    "            # ... rest of the code ...\n",
    "        else:\n",
    "            print(\"Loss does not require grad\")\n",
    "            return None, None\n",
    "        # loss.backward()\n",
    "        # grad = points.grad\n",
    "        # # saliency map calculations\n",
    "        sphere_core = torch.median(points, axis=2, keepdims=True)  # B * 3 * 1\n",
    "\n",
    "        sphere_r = torch.sqrt(torch.sum(torch.square(\n",
    "            points - sphere_core.values), axis=1))  # B * 1024\n",
    "\n",
    "        sphere_axis = points - sphere_core.values  # B * 3 * 1024\n",
    "\n",
    "        before_map = torch.sum(torch.multiply(\n",
    "            grad, sphere_axis), axis=1)  # B * 1024\n",
    "\n",
    "        map = -torch.multiply(before_map,\n",
    "                              torch.pow(sphere_r, alpha))  # B * 1024\n",
    "\n",
    "        drop_indices = torch.topk(map, a).indices  # B * n/T\n",
    "\n",
    "        tmp = torch.zeros((points.shape[0], 3, points.shape[2] - a))\n",
    "        numpy_points = points.cpu().detach().numpy()\n",
    "        numpy_indices = drop_indices.cpu().detach().numpy()\n",
    "        for j in range(points.shape[0]):\n",
    "            saliency_points[j][:, i *\n",
    "                               a: (i + 1) * a] = numpy_points[j][:, numpy_indices[j]]\n",
    "            tmp[j] = torch.from_numpy(\n",
    "                np.delete(numpy_points[j], numpy_indices[j], axis=1))\n",
    "\n",
    "        points = tmp.detach().clone()\n",
    "\n",
    "    # returns the points after dropping the most important ones and the most important points\n",
    "    return points, saliency_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 795602,
     "status": "ok",
     "timestamp": 1645111485765,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "W31lOKsivQMt",
    "outputId": "94d1daf4-bc21-4657-9bab-e34de96296ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1024, 3])\n",
      "torch.Size([16])\n",
      "Loss does not require grad\n",
      "None\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "# Ensure the model is on the correct device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "classifier.to(device)\n",
    "\n",
    "# Evaluate model\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testDataLoader:\n",
    "        points, labels = data\n",
    "        points = points.to(device)  # Move points to the same device as the model\n",
    "        labels = labels.to(device)  # Move labels to the same device as the model\n",
    "\n",
    "        # Print shapes for debugging\n",
    "        print(points.shape)\n",
    "        print(labels.shape)\n",
    "\n",
    "        # Call the dynamic saliency map function\n",
    "        new_points, saliency_points = dynamic_saliency_map(\n",
    "            model=classifier, points=points, labels=labels, device=device, n=200, T=40\n",
    "        )\n",
    "        \n",
    "        # Process the output as needed\n",
    "        print(new_points)\n",
    "        break  # Remove this break to process the entire dataset\n",
    "    \n",
    "i = False\n",
    "j = 0\n",
    "for data in testDataLoader:\n",
    "    points, labels = data\n",
    "    new_points, saliency_points = dynamic_saliency_map(model=model, points=points, labels=labels, device=device, n = 200, T = 40)\n",
    "    if i is False:\n",
    "        final_set = new_points.cpu().detach().numpy()\n",
    "        i = True\n",
    "    else:\n",
    "        final_set = np.append(final_set, new_points, axis = 0)\n",
    "    print(j)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1645111486507,
     "user": {
      "displayName": "hanieh naderi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16720363327659797595"
     },
     "user_tz": -210
    },
    "id": "bVNCdwGNvERl"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# # 假设new_points是三维点云数据\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(new_points[:, 0], new_points[:, 1], new_points[:, 2])\n",
    "# plt.show()\n",
    "# to_save = final_set.transpose(0, 2, 1)\n",
    "# np.save('Data/drop200_pointnet2/test_data.npy', to_save)\n",
    "\n",
    "#Ensure the directory exists\n",
    "output_dir = 'Data/drop200_pointnet2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the file\n",
    "to_save = final_set.transpose(0, 2, 1)\n",
    "np.save(os.path.join(output_dir, 'test_data.npy'), to_save)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}